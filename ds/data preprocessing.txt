#Data Preprocessing
#Import packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
#import dataset
dataset = pd.read_csv('E:\\6th Sem\DATA SCIENCE\Dataset.csv')
dataset
X = dataset.iloc[:,:-1].values
# Until the last column (based on indexing it will not include last column). 
Y= dataset.iloc[:, -1].values
# only last column
print(X)
#Taking care of missing data 
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan,strategy='mean')
imputer.fit(X[:, 1:3])
X[:, 1:3] = imputer.transform(X[:, 1:3])
print(X)
#Encoding categorical data
#Encoding the Independent Variable 
from sklearn.compose import ColumnTransformer
# applies transformers to columns of an array or pandas Data Frame 

from sklearn.preprocessing import OneHotEncoder 

ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough') 
X = np.array(ct.fit_transform(X))
print(X)
#Encoding the Dependent Variable
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(Y)
print(y)
# Splitting the dataset into the Training set and Test set 
from sklearn.model_selection import train_test_split 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1) 
print(X_train) 
print(X_test) 
print(y_train)
print(y_test) 
#Feature Scaling
# StandardScalerâ€¯standardizes a feature by subtracting the mean and then scaling to unit variance. 
from sklearn.preprocessing import StandardScaler 
sc = StandardScaler() 
#Transform the data
X_train[:, 3:] = sc.fit_transform(X_train[:, 3:]) 
X_test[:, 3:] = sc.transform(X_test[:, 3:]) 

print(X_train) 
print(X_test)